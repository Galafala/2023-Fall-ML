{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](07hw1p.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.jpg](07hw2p.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([[-1, 1, 1], [1, 1, 1], [0, 0, 0]])\n",
    "y = np.array([0, 1, 0])\n",
    "\n",
    "x1 = np.linspace(-2, 2, 1000)\n",
    "x2 = pow(x1, 2) + 1/2\n",
    "\n",
    "x1_point = [-1, 1, 0]\n",
    "x2_point = [1, 1, 0]\n",
    "plt.plot(x1, x2, 'orange')\n",
    "plt.scatter(x1_point, x2_point)\n",
    "plt.scatter(0, 1)\n",
    "plt.ylim(-1, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents = sio.loadmat('07HW2_digit.mat')\n",
    "train_data = np.array([mat_contents[key].astype(float) for key in mat_contents.keys() if key.startswith('train')])\n",
    "test_data = np.array([mat_contents[key].astype(float) for key in mat_contents.keys() if key.startswith('test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    return (data - min_val) / (max_val - min_val)\n",
    "\n",
    "train_data = normalize(train_data)\n",
    "test_data = normalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gammas = [2**i for i in range(-14, -5)]\n",
    "Cs = [2**i for i in range(-5, 4)]\n",
    "\n",
    "train_class = np.repeat(range(2), train_data[0].shape[0])\n",
    "test_class = np.repeat(range(2), test_data[0].shape[0])\n",
    "train = np.append(train_data[0, :], train_data[1, :], axis=0)\n",
    "test = np.append(test_data[0, :], test_data[1, :], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.94  0.94  0.94  0.94  0.985 0.99  0.995 1.    1.   ]\n",
      " [0.94  0.94  0.94  0.985 0.99  0.995 1.    1.    1.   ]\n",
      " [0.94  0.94  0.985 0.99  0.995 1.    1.    1.    1.   ]\n",
      " [0.945 0.985 0.99  0.995 1.    1.    1.    1.    1.   ]\n",
      " [0.985 0.99  0.995 1.    1.    1.    1.    1.    1.   ]\n",
      " [0.99  0.995 1.    1.    1.    1.    1.    1.    1.   ]\n",
      " [0.995 1.    1.    1.    1.    1.    1.    1.    1.   ]\n",
      " [1.    1.    1.    1.    1.    1.    1.    1.    1.   ]\n",
      " [1.    1.    1.    1.    1.    1.    1.    1.    1.   ]]\n"
     ]
    }
   ],
   "source": [
    "acc_matrix = np.zeros((len(Gammas), len(Cs)))\n",
    "\n",
    "for i, gamma in enumerate(Gammas):\n",
    "    for j, C in enumerate(Cs):\n",
    "        clf = svm.SVC(kernel='rbf', gamma=gamma, C=C)\n",
    "        clf.fit(train, train_class)\n",
    "        acc_matrix[i, j] = clf.score(test, test_class)\n",
    "\n",
    "print(acc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best piar of gamma and C is a lot, so I choose $gamma=2^{-6}$ and $C=2^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "acc_matrix = np.zeros((len(Gammas), len(Cs)))\n",
    "\n",
    "for i, gamma in enumerate(Gammas):\n",
    "    for j, C in enumerate(Cs):\n",
    "        clf = svm.SVC(kernel='linear', gamma=gamma, C=C)\n",
    "        clf.fit(train, train_class)\n",
    "        acc_matrix[i, j] = clf.score(test, test_class)\n",
    "\n",
    "print(acc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degeree 1\n",
      "[[0.94  0.94  0.94  0.94  0.94  0.985 0.99  0.995 1.   ]\n",
      " [0.94  0.94  0.94  0.94  0.985 0.99  0.995 1.    1.   ]\n",
      " [0.94  0.94  0.94  0.985 0.99  0.995 1.    1.    1.   ]\n",
      " [0.94  0.94  0.985 0.99  0.995 1.    1.    1.    1.   ]\n",
      " [0.94  0.985 0.99  0.995 1.    1.    1.    1.    1.   ]\n",
      " [0.985 0.99  0.995 1.    1.    1.    1.    1.    1.   ]\n",
      " [0.99  0.995 1.    1.    1.    1.    1.    1.    1.   ]\n",
      " [0.995 1.    1.    1.    1.    1.    1.    1.    1.   ]\n",
      " [1.    1.    1.    1.    1.    1.    1.    1.    1.   ]]\n",
      "Degeree 2\n",
      "[[0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.575]\n",
      " [0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.575]\n",
      " [0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.575 0.69 ]\n",
      " [0.575 0.575 0.575 0.575 0.575 0.575 0.69  0.84  0.92 ]\n",
      " [0.575 0.575 0.575 0.575 0.69  0.84  0.92  0.955 0.99 ]\n",
      " [0.575 0.575 0.69  0.84  0.92  0.955 0.99  0.99  0.995]\n",
      " [0.69  0.84  0.92  0.955 0.99  0.99  0.995 1.    1.   ]\n",
      " [0.92  0.955 0.99  0.99  0.995 1.    1.    1.    1.   ]\n",
      " [0.99  0.99  0.995 1.    1.    1.    1.    1.    1.   ]]\n",
      "Degeree 3\n",
      "[[0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535]\n",
      " [0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535]\n",
      " [0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535]\n",
      " [0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.535]\n",
      " [0.535 0.535 0.535 0.535 0.535 0.535 0.535 0.57  0.64 ]\n",
      " [0.535 0.535 0.535 0.535 0.57  0.64  0.725 0.825 0.855]\n",
      " [0.535 0.57  0.64  0.725 0.825 0.855 0.93  0.96  0.98 ]\n",
      " [0.725 0.825 0.855 0.93  0.96  0.98  0.985 0.99  0.99 ]\n",
      " [0.93  0.96  0.98  0.985 0.99  0.99  0.995 0.995 0.995]]\n"
     ]
    }
   ],
   "source": [
    "for d in range(1, 4):\n",
    "    acc_matrix = np.zeros((len(Gammas), len(Cs)))\n",
    "    for i, gamma in enumerate(Gammas):\n",
    "        for j, C in enumerate(Cs):\n",
    "            clf = svm.SVC(kernel='poly', gamma=gamma, C=C, degree=d)\n",
    "            clf.fit(train, train_class)\n",
    "            acc_matrix[i, j] = clf.score(test, test_class)\n",
    "\n",
    "    print(f'Degeree {d}')\n",
    "    print(acc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a linear kernel, the accuraies are all 100%.\n",
    "\n",
    "With polynomial kernels, the higher the degrees the lower the accuracy. Therefore, I would like to choose Degree1 kernel. Not only is the accuracy, but also it has less computational cost. The pairs of gamma and C are $gamma=2^{-14}$ and $C=2^3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, target_class):\n",
    "    other_classes = [i for i in range(10) if i != target_class]\n",
    "\n",
    "    # Get data for the target class\n",
    "    target_data = data[target_class]\n",
    "\n",
    "    # Get data for the other classes\n",
    "    other_data = data[other_classes].reshape(-1, data.shape[2])\n",
    "\n",
    "    # Create class labels for target and others\n",
    "    target_labels = np.ones(target_data.shape[0])  # Labels for target class (1)\n",
    "    other_labels = np.ones(other_data.shape[0], dtype=np.uint8)*-1   # Labels for other classes (0)\n",
    "\n",
    "    # Combine target and other data, and their respective labels\n",
    "    class_data = np.concatenate((target_data, other_data), axis=0)\n",
    "    class_labels = np.concatenate((target_labels, other_labels), axis=0)\n",
    "\n",
    "    class_data = normalize(class_data)\n",
    "\n",
    "    return class_data, class_labels\n",
    "\n",
    "\n",
    "def train_svm(train, train_class, test, test_class, gamma, C, kernel='rbf', degree=3):\n",
    "    if kernel == 'poly':\n",
    "        clf = svm.SVC(kernel=kernel, gamma=gamma, C=C, degree=degree)\n",
    "    else:\n",
    "        clf = svm.SVC(kernel=kernel, gamma=gamma, C=C)\n",
    "\n",
    "    clf.fit(train, train_class)\n",
    "    \n",
    "    # Calculate predictions on test data\n",
    "    predictions = clf.predict(test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(test_class, predictions)\n",
    "    ap = average_precision_score(test_class, predictions)\n",
    "    precision = precision_score(test_class, predictions, zero_division=0)\n",
    "    f1 = f1_score(test_class, predictions, zero_division=0)\n",
    "    recall = recall_score(test_class, predictions, zero_division=0)\n",
    "\n",
    "    return accuracy, f1, recall, precision, ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mAP: 0.8976153307855922\n",
      "Best accuracy: 0.9888\n",
      "Best precision: 0.9663575403949783\n",
      "Best recall: 0.9200000000000002\n",
      "Best f1: 0.9423856767547008\n",
      "Best gamma: 0.015625\n",
      "Best C: 8\n"
     ]
    }
   ],
   "source": [
    "Gammas = [2**i for i in range(-14, -5)]\n",
    "Cs = [2**i for i in range(-5, 4)]\n",
    "\n",
    "best_ap = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "best_precision = 0\n",
    "\n",
    "best_gamma = 0\n",
    "best_C = 0\n",
    "\n",
    "for gamma in tqdm(Gammas):\n",
    "    for C in Cs:\n",
    "        acc, f1, recall, precision, ap = [0]*10, [0]*10, [0]*10, [0]*10, [0]*10\n",
    "        for target_class in range(10):\n",
    "            train, train_class = prepare_data(train_data, target_class)\n",
    "            test, test_class = prepare_data(test_data, target_class)\n",
    "\n",
    "            acc[target_class], f1[target_class], recall[target_class], precision[target_class], ap[target_class] = \\\n",
    "                train_svm(train, train_class, test, test_class, gamma, C, kernel='rbf')\n",
    "\n",
    "        ap = np.mean(ap)\n",
    "        if ap > best_ap:\n",
    "            best_ap = ap\n",
    "            best_acc = np.mean(acc)\n",
    "            best_f1 = np.mean(f1)\n",
    "            best_recall = np.mean(recall)\n",
    "            best_precision = np.mean(precision)\n",
    "            best_gamma = gamma\n",
    "            best_C = C\n",
    "\n",
    "print(f'Best mAP: {best_ap}')\n",
    "print(f'Best accuracy: {best_acc}')\n",
    "print(f'Best precision: {best_precision}')\n",
    "print(f'Best recall: {best_recall}')\n",
    "print(f'Best f1: {best_f1}')\n",
    "print(f'Best gamma: {best_gamma}')\n",
    "print(f'Best C: {best_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [16:07<00:00, 107.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mAP: 0.7786100549992834\n",
      "Best accuracy: 0.9753000000000001\n",
      "Best precision: 0.9169169846353811\n",
      "Best recall: 0.827\n",
      "Best f1: 0.8687618854637064\n",
      "Best gamma: 6.103515625e-05\n",
      "Best C: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Gammas = [2**i for i in range(-14, -5)]\n",
    "Cs = [2**i for i in range(-5, 4)]\n",
    "\n",
    "best_ap = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "best_precision = 0\n",
    "\n",
    "best_gamma = 0\n",
    "best_C = 0\n",
    "\n",
    "for gamma in tqdm(Gammas):\n",
    "    for C in Cs:\n",
    "        acc, f1, recall, precision, ap = [0]*10, [0]*10, [0]*10, [0]*10, [0]*10\n",
    "        for target_class in range(10):\n",
    "            train, train_class = prepare_data(train_data, target_class)\n",
    "            test, test_class = prepare_data(test_data, target_class)\n",
    "\n",
    "            acc[target_class], f1[target_class], recall[target_class], precision[target_class], ap[target_class] = \\\n",
    "                train_svm(train, train_class, test, test_class, gamma, C, kernel='linear')\n",
    "\n",
    "        ap = np.mean(ap)\n",
    "        if ap > best_ap:\n",
    "            best_ap = ap\n",
    "            best_acc = np.mean(acc)\n",
    "            best_f1 = np.mean(f1)\n",
    "            best_recall = np.mean(recall)\n",
    "            best_precision = np.mean(precision)\n",
    "            best_gamma = gamma\n",
    "            best_C = C\n",
    "\n",
    "print(f'Best mAP: {best_ap}')\n",
    "print(f'Best accuracy: {best_acc}')\n",
    "print(f'Best precision: {best_precision}')\n",
    "print(f'Best recall: {best_recall}')\n",
    "print(f'Best f1: {best_f1}')\n",
    "print(f'Best gamma: {best_gamma}')\n",
    "print(f'Best C: {best_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [27:50<00:00, 185.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 2\n",
      "Best mAP: 0.8847781065867253\n",
      "Best accuracy: 0.9873999999999998\n",
      "Best precision: 0.9550824520804057\n",
      "Best recall: 0.917\n",
      "Best f1: 0.9355260790930702\n",
      "Best gamma: 0.015625\n",
      "Best C: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [28:54<00:00, 192.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 3\n",
      "Best mAP: 0.8847781065867253\n",
      "Best accuracy: 0.9873999999999998\n",
      "Best precision: 0.9550824520804057\n",
      "Best recall: 0.917\n",
      "Best f1: 0.9355260790930702\n",
      "Best gamma: 0.015625\n",
      "Best C: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [29:33<00:00, 197.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 4\n",
      "Best mAP: 0.8847781065867253\n",
      "Best accuracy: 0.9873999999999998\n",
      "Best precision: 0.9550824520804057\n",
      "Best recall: 0.917\n",
      "Best f1: 0.9355260790930702\n",
      "Best gamma: 0.015625\n",
      "Best C: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Gammas = [2**i for i in range(-14, -5)]\n",
    "Cs = [2**i for i in range(-5, 4)]\n",
    "\n",
    "best_ap = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "best_recall = 0\n",
    "best_precision = 0\n",
    "\n",
    "best_gamma = 0\n",
    "best_C = 0\n",
    "\n",
    "for d in range(2, 5):\n",
    "    for gamma in tqdm(Gammas):\n",
    "        for C in Cs:\n",
    "            acc, f1, recall, precision, ap = [0]*10, [0]*10, [0]*10, [0]*10, [0]*10\n",
    "            for target_class in range(10):\n",
    "                train, train_class = prepare_data(train_data, target_class)\n",
    "                test, test_class = prepare_data(test_data, target_class)\n",
    "\n",
    "                acc[target_class], f1[target_class], recall[target_class], precision[target_class], ap[target_class] = \\\n",
    "                    train_svm(train, train_class, test, test_class, gamma, C, kernel='poly', degree=d)\n",
    "\n",
    "            ap = np.mean(ap)\n",
    "            if ap > best_ap:\n",
    "                best_ap = ap\n",
    "                best_acc = np.mean(acc)\n",
    "                best_f1 = np.mean(f1)\n",
    "                best_recall = np.mean(recall)\n",
    "                best_precision = np.mean(precision)\n",
    "                best_gamma = gamma\n",
    "                best_C = C\n",
    "\n",
    "    print(f'Degree {d}')\n",
    "    print(f'Best mAP: {best_ap}')\n",
    "    print(f'Best accuracy: {best_acc}')\n",
    "    print(f'Best precision: {best_precision}')\n",
    "    print(f'Best recall: {best_recall}')\n",
    "    print(f'Best f1: {best_f1}')\n",
    "    print(f'Best gamma: {best_gamma}')\n",
    "    print(f'Best C: {best_C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy\n",
    "\n",
    "I used one by others method. In other words, I choose a number which I want to classify, and I other as the same type. By doing so, I can reamain SVM as a two classes classification task. Then I will repeat the process for 10 numbers, and will calculate the mean value of their respective accuracy. So I can get a model to classify the 10 numbers!\n",
    "\n",
    "\n",
    "### Final Result\n",
    "\n",
    "#### Kernel: rbf <br>\n",
    "Best mAP: 0.8976153307855922<br>\n",
    "Best accuracy: 0.9888<br>\n",
    "Best precision: 0.9663575403949783<br>\n",
    "Best recall: 0.9200000000000002<br>\n",
    "Best f1: 0.9423856767547008<br>\n",
    "Best gamma: 0.015625<br>\n",
    "Best C: 8<br>\n",
    "\n",
    "#### Kernel: linear<br>\n",
    "Best mAP: 0.7786100549992834<br>\n",
    "Best accuracy: 0.9753000000000001<br>\n",
    "Best precision: 0.9169169846353811<br>\n",
    "Best recall: 0.827<br>\n",
    "Best f1: 0.8687618854637064<br>\n",
    "Best gamma: 6.103515625e-05<br>\n",
    "Best C: 0.0625<br>\n",
    "\n",
    "#### Kernel: poly<br>\n",
    "Degree 2<br>\n",
    "Best mAP: 0.8847781065867253<br>\n",
    "Best accuracy: 0.9873999999999998<br>\n",
    "Best precision: 0.9550824520804057<br>\n",
    "Best recall: 0.917<br>\n",
    "Best f1: 0.9355260790930702<br>\n",
    "Best gamma: 0.015625<br>\n",
    "Best C: 8<br>\n",
    "\n",
    "Degree 3<br>\n",
    "Best mAP: 0.8847781065867253<br>\n",
    "Best accuracy: 0.9873999999999998<br>\n",
    "Best precision: 0.9550824520804057<br>\n",
    "Best recall: 0.917<br>\n",
    "Best f1: 0.9355260790930702<br>\n",
    "Best gamma: 0.015625<br>\n",
    "Best C: 8<br>\n",
    "\n",
    "Degree 4<br>\n",
    "Best mAP: 0.8847781065867253<br>\n",
    "Best accuracy: 0.9873999999999998<br>\n",
    "Best precision: 0.9550824520804057<br>\n",
    "Best recall: 0.917<br>\n",
    "Best f1: 0.9355260790930702<br>\n",
    "Best gamma: 0.015625<br>\n",
    "Best C: 8<br>\n",
    "\n",
    "#### Discussion\n",
    "\n",
    "By comparing the mAP with different kernels, the **rbf** has the best performance. However the result might not be the best because the method we find the gamma and C is not precise. If we want to find the best gamma and C, we can train the model with gradient decent to find a piar of gamma and C where is minima."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
